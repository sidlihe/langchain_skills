{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "517d43c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import TypedDict, List\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage\n",
    "from langgraph.graph import StateGraph, END\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ea774ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SiddheshLihe\\langhchain_skills\\module_1\\langgraph\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01a48665",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEMORY_FILE = \"memory.json\"\n",
    "\n",
    "class ChatState(TypedDict):\n",
    "    messages: List[BaseMessage]\n",
    "    user_name: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dd87860f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading memory\n",
    "def load_memory():\n",
    "    if os.path.exists(MEMORY_FILE):\n",
    "        with open(MEMORY_FILE, \"r\") as f:\n",
    "            return json.load(f)\n",
    "    return {}\n",
    "\n",
    "def save_memory(memory):\n",
    "    with open(MEMORY_FILE, \"w\") as f:\n",
    "        json.dump(memory, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b5741cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    api_key=os.getenv(\"GROQ_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f3aa3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Node: Extract User Name\n",
    "def extract_user_info(state: ChatState) -> ChatState:\n",
    "    user_msg = state[\"messages\"][-1].content.lower()\n",
    "\n",
    "    memory = load_memory()\n",
    "\n",
    "    if \"my name is\" in user_msg:\n",
    "        name = user_msg.split(\"my name is\")[-1].strip()\n",
    "        memory[\"user_name\"] = name\n",
    "        save_memory(memory)\n",
    "        print(\" Saved name to memory:\", name)\n",
    "\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b483c84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Node: LLM Response\n",
    "def generate_response(state: ChatState) -> ChatState:\n",
    "    memory = load_memory()\n",
    "\n",
    "    system_prompt = \"You are a helpful AI assistant.\"\n",
    "\n",
    "    if \"user_name\" in memory:\n",
    "        system_prompt += f\" The user's name is {memory['user_name']}.\"\n",
    "\n",
    "    full_messages = [HumanMessage(content=system_prompt)] + state[\"messages\"]\n",
    "\n",
    "    response = llm.invoke(full_messages)\n",
    "\n",
    "    print(\" LLM CALLED\")\n",
    "    print(\" Input Messages:\", full_messages)\n",
    "    print(\" Output:\", response.content)\n",
    "\n",
    "    return {\n",
    "        \"messages\": state[\"messages\"] + [response],\n",
    "        \"user_name\": memory.get(\"user_name\", \"\")\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0046f0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = StateGraph(ChatState)\n",
    "\n",
    "builder.add_node(\"Extract_user\",extract_user_info)\n",
    "builder.add_node(\"Generate_response\",generate_response)\n",
    "\n",
    "builder.set_entry_point(\"Extract_user\")\n",
    "\n",
    "builder.add_edge(\"Extract_user\", \"Generate_response\")\n",
    "builder.add_edge(\"Generate_response\", END)\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8520c04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#chat_loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ed5f1067",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = {\n",
    "    \"messages\": [],\n",
    "    \"user_name\": \"\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3c907c9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbd228e6dbdd458ca0821bb83d8b934e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', placeholder='Type your message here')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57d0abfa2a044bb79a25b75ffca29104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Send', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "290cfcad0f6c4b07b59fb65ed3529381",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display\n",
    "import ipywidgets as widgets\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Initialize state\n",
    "state = {\"messages\": []}\n",
    "\n",
    "# Create widgets\n",
    "text = widgets.Text(placeholder=\"Type your message here\")\n",
    "send = widgets.Button(description=\"Send\")\n",
    "out = widgets.Output()\n",
    "\n",
    "def on_send(b):\n",
    "    user_input = text.value.strip()\n",
    "    if not user_input:\n",
    "        return\n",
    "    \n",
    "    # Exit condition\n",
    "    if user_input.lower() in [\"exit\", \"quit\", \"bye\"]:\n",
    "        with out:\n",
    "            print(\"\\nðŸ‘‹ Chat ended.\")\n",
    "        text.disabled = True\n",
    "        send.disabled = True\n",
    "        return\n",
    "\n",
    "    # Show user input\n",
    "    with out:\n",
    "        print(\"\\nYou:\", user_input)\n",
    "\n",
    "    # Append to state\n",
    "    state[\"messages\"].append(HumanMessage(content=user_input))\n",
    "\n",
    "    # Invoke graph\n",
    "    new_state = graph.invoke(state)\n",
    "\n",
    "    # Show AI response\n",
    "    with out:\n",
    "        print(\"AI:\", new_state[\"messages\"][-1].content)\n",
    "\n",
    "    # Update state\n",
    "    state.update(new_state)\n",
    "\n",
    "    # Clear text box\n",
    "    text.value = \"\"\n",
    "\n",
    "# Bind button click\n",
    "send.on_click(on_send)\n",
    "\n",
    "# Display UI\n",
    "display(text, send, out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "292536fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "termloop\n"
     ]
    }
   ],
   "source": [
    "print(\"termloop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57f1dc6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
